{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2mbi1bR16YS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b2mbi1bR16YS",
        "outputId": "4def89ac-46ab-4aa6-98e7-f29c5f3faea8"
      },
      "outputs": [],
      "source": [
        "%pip install tqdm pandas OpenAI\n",
        "%pip install pypdf\n",
        "%pip install python-dotenv\n",
        "%pip install -q transformers einops accelerate langchain bitsandbytes\n",
        "%pip install sentence_transformers\n",
        "%pip install llama_index==0.9.9\n",
        "%pip install -U langchain-community\n",
        "%pip install anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0f22158f-4067-477f-990d-343521f0a1f7",
      "metadata": {
        "id": "0f22158f-4067-477f-990d-343521f0a1f7"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f3e99bed-382b-48f8-80a4-c8b238f75b74",
      "metadata": {
        "id": "f3e99bed-382b-48f8-80a4-c8b238f75b74"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(api_key = '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')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a5f5eb5a-d410-4cfa-9776-b8b08c16c76f",
      "metadata": {
        "id": "a5f5eb5a-d410-4cfa-9776-b8b08c16c76f"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "  name=\"Data Analyst\",\n",
        "  instructions=\"You are an expert Data Analyst. Use your knowledge base to answer questions about the reports. Keep your answers as brief as possible. In your answers, specify only the data for FY 2022-23, and only mention the answer along with the unit mentioned in each query. Avoid extraneous output. Do not make assumptions and be as accurate as possible.\",\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  tools=[{\"type\": \"file_search\"}],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "247bc3d6-9545-4dc8-8b34-ec91993c6bc4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "247bc3d6-9545-4dc8-8b34-ec91993c6bc4",
        "outputId": "9497f9fe-6cf2-4c6f-9f78-6113c606fa87"
      },
      "outputs": [],
      "source": [
        "n = input(\"Enter name of vector store: \")\n",
        "vector_store = client.beta.vector_stores.create(name=str(n))\n",
        "filepath = input(\"Filename: \")\n",
        "\n",
        "file_paths = [str(filepath)]\n",
        "file_streams = [open(file_path, \"rb\") for file_path in file_paths]\n",
        "\n",
        "try:\n",
        "    file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
        "        vector_store_id=vector_store.id, files=file_streams\n",
        "    )\n",
        "    print(file_batch.status)\n",
        "    print(file_batch.file_counts)\n",
        "finally:\n",
        "    for stream in file_streams:\n",
        "        stream.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "ba23e024-c6ee-4dc4-920d-019ecc8f48b6",
      "metadata": {
        "id": "ba23e024-c6ee-4dc4-920d-019ecc8f48b6"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.update(\n",
        "  assistant_id=assistant.id,\n",
        "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "3c55cf60-44c2-4fbc-ac2c-73e18d169aa8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "3c55cf60-44c2-4fbc-ac2c-73e18d169aa8",
        "outputId": "e924dbbe-27a9-4049-991c-a363c9a1405f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The total Scope 1 emissions generated in FY 2022-23 were 31,259 metric tonnes of CO2 equivalent[0].\n",
            "[0] Bharati Airtel BRSR report 2022-23.pdf\n"
          ]
        }
      ],
      "source": [
        "## for individual queries and testing\n",
        "thread = client.beta.threads.create(\n",
        "  messages=[\n",
        "    {\"role\": \"user\",\"content\": \"Total Scope 1 emissions generated in latest FY.\",}\n",
        "  ]\n",
        ")\n",
        "run = client.beta.threads.runs.create_and_poll(\n",
        "    thread_id=thread.id, assistant_id=assistant.id\n",
        ")\n",
        "\n",
        "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
        "\n",
        "message_content = messages[0].content[0].text\n",
        "annotations = message_content.annotations\n",
        "citations = []\n",
        "for index, annotation in enumerate(annotations):\n",
        "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
        "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "        cited_file = client.files.retrieve(file_citation.file_id)\n",
        "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "\n",
        "print(message_content.value)\n",
        "print(\"\\n\".join(citations))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "cf1d1367-cedd-439e-9959-dbaebbaf9d8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "cf1d1367-cedd-439e-9959-dbaebbaf9d8f",
        "outputId": "1c0d81bd-73ed-44d2-b576-eb793b00c539"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('BRSR extraction data points modified.xlsx')#excel containing the questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "f5cff10a-ea3d-4ea4-9640-3ca2a3ee594c",
      "metadata": {
        "id": "f5cff10a-ea3d-4ea4-9640-3ca2a3ee594c",
        "outputId": "7adef957-e517-4e45-8e26-55414ef6cac8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 78/78 [07:50<00:00,  6.04s/it]\n"
          ]
        }
      ],
      "source": [
        "#function to run on queries present in the column\n",
        "def get_answer(question, section):\n",
        "    thread = client.beta.threads.create(\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": question}\n",
        "        ]\n",
        "    )\n",
        "    run = client.beta.threads.runs.create_and_poll(\n",
        "        thread_id=thread.id, assistant_id=assistant.id\n",
        "    )\n",
        "    messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
        "\n",
        "    if not messages:\n",
        "        return \"No response received.\"\n",
        "\n",
        "    message_content = messages[0].content[0].text\n",
        "    annotations = message_content.annotations\n",
        "    citations = []\n",
        "    for index, annotation in enumerate(annotations):\n",
        "        message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
        "        if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "            cited_file = client.files.retrieve(file_citation.file_id)\n",
        "            citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "    answer = message_content.value + \"\\n\" + \"\\n\".join(citations)\n",
        "    return answer\n",
        "\n",
        "tqdm.pandas()\n",
        "df['Answer'] = df.progress_apply(lambda row: get_answer(row['Data Points'], row['Section/ Point']), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "c48397f2-0f62-4b8a-af97-12e27ee94bb9",
      "metadata": {
        "id": "c48397f2-0f62-4b8a-af97-12e27ee94bb9"
      },
      "outputs": [],
      "source": [
        "grouped = df.groupby('Area of Analysis')\n",
        "for category, group_df in grouped:\n",
        "    file_name = f\"{category}.xlsx\"\n",
        "    group_df.to_excel(file_name, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "a96a6cb0-9b59-4005-afaf-09e95025905f",
      "metadata": {
        "id": "a96a6cb0-9b59-4005-afaf-09e95025905f"
      },
      "outputs": [],
      "source": [
        "df.to_excel(\"Ragresults.xlsx\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
